{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLE Assessed Coursework 3: Question 3\n",
    "\n",
    "For this assessment, you are expected to complete and submit 4 notebook files.  There is 1 notebook file for each question (to speed up load times).  This is notebook 3 out of 4.\n",
    "\n",
    "Marking guidelines are provided as a separate document.\n",
    "\n",
    "In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateno=184514 #this MUST be updated to your candidate number so that you get a unique data sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sussex NLTK root directory is /Users/Bayley/Documents/resources\n"
     ]
    }
   ],
   "source": [
    "#preliminary imports\n",
    "import sys\n",
    "sys.path.append(r'\\\\ad.susx.ac.uk\\ITS\\TeachingResources\\Departments\\Informatics\\LanguageEngineering\\resources')\n",
    "sys.path.append(r'/Users/juliewe/resources')\n",
    "sys.path.append(r'/Users/Bayley/Documents/resources')\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools import zip_longest\n",
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import math\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Named Entity Recognition and Linking (25 marks)\n",
    "\n",
    "The code below will run the SpaCy system on the text from Persuasion by Jane Austen.  `mysample` contains a 50% sample which is unique to your candidate number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do NOT change the code in this cell.\n",
    "\n",
    "#preparing corpus\n",
    "\n",
    "def clean_text(astring):\n",
    "    #replace newlines with space\n",
    "    newstring=re.sub(\"\\n\",\" \",astring)\n",
    "    #remove title and chapter headings\n",
    "    newstring=re.sub(\"\\[[^\\]]*\\]\",\" \",newstring)\n",
    "    newstring=re.sub(\"VOLUME \\S+\",\" \",newstring)\n",
    "    newstring=re.sub(\"CHAPTER \\S+\",\" \",newstring)\n",
    "    newstring=re.sub(\"\\s\\s+\",\" \",newstring)\n",
    "    #return re.sub(\"([^\\.|^ ])  +\",r\"\\1 .  \",newstring).lstrip().rstrip()\n",
    "    return newstring.lstrip().rstrip()\n",
    "\n",
    "\n",
    "def get_sample(sentslist,seed=candidateno):\n",
    "    random.seed(seed)\n",
    "    random.shuffle(sentslist)\n",
    "    testsize=int(len(sentslist)/2)\n",
    "    return sentslist[testsize:]\n",
    "    \n",
    "persuasion=clean_text(gutenberg.raw('austen-persuasion.txt'))\n",
    "nlp_persuasion=list(nlp(persuasion).sents)\n",
    "\n",
    "mysample=get_sample(nlp_persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mysample[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) **Write code** and **extract**:\n",
    "* the 30 most common strings referring to PEOPLE in `mysample`.\n",
    "* the 30 most common strings referring to PLACES in `mysample`.\n",
    "\n",
    "\\[6 marks\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Most common strings referring to PEOPLE \n",
      " [('Anne', 206), ('Elliot', 146), ('Wentworth', 95), ('Lady Russell', 78), ('Mary', 67), ('Walter', 67), ('Captain Wentworth', 62), ('Musgrove', 60), ('Charles', 60), ('Russell', 60), ('Elizabeth', 47), ('Harville', 36), ('Benwick', 27), ('Smith', 25), ('Mrs Musgrove', 21), ('Clay', 21), ('Captain Benwick', 20), ('Mrs Clay', 19), ('Charles Hayter', 19), ('Louisa', 18), ('Hayter', 18), ('Shepherd', 18), (\"Russell 's\", 18), ('Wallis', 15), ('Captain Harville', 14), ('Mrs Smith', 13), ('Anne Elliot', 12), ('Mr Shepherd', 12), ('Lady Dalrymple', 11), ('Dalrymple', 10)] \n",
      "\n",
      "30 Most common strings referring to PLACES \n",
      " [('Uppercross', 30), ('Camden Place', 12), ('Place', 12), ('Lyme', 10), ('Kellynch', 9), ('London', 9), ('Indies', 6), ('the West', 5), ('West Indies', 5), ('Plymouth', 3), ('Monkford', 3), ('England', 3), ('Shropshire', 3), ('Cape', 2), ('Westgate Buildings', 2), ('Buildings', 2), ('Ireland', 2), ('Winthrop', 2), ('the East', 1), ('East Indies', 1), ('Mediterranean', 1), ('Mrs Musgrove', 1), ('Musgrove', 1), ('Mrs Wallis', 1), ('Wallis', 1), ('Grappler', 1), ('Temple', 1), ('the North', 1), ('North Seas', 1), ('Seas', 1)]\n"
     ]
    }
   ],
   "source": [
    "def display_sent(asent):\n",
    "    headings=[\"token\",\"lower\",\"lemma\",\"pos\",\"NER\"]\n",
    "    info=[]\n",
    "    for t in asent:\n",
    "        info.append([t.text,t.lower_,t.lemma_,t.pos_,t.ent_type_])\n",
    "    return(pd.DataFrame(info,columns=headings))\n",
    "\n",
    "def token_func(sents):\n",
    "    token_list = []\n",
    "    POS_tags = []\n",
    "    entity_tags = []\n",
    "    for sent in sents:\n",
    "        table = display_sent(sent)\n",
    "        for item in table['token']:\n",
    "            token_list += [item]\n",
    "        for item in table['pos']:\n",
    "            POS_tags += [item]\n",
    "        for item in table['NER']:\n",
    "            entity_tags += [item]\n",
    "    return token_list, POS_tags, entity_tags\n",
    "\n",
    "token_list, tag_list, entity_tags = token_func(mysample)\n",
    "\n",
    "def tag_type(token_list, tag_list, tag_type):\n",
    "    tag_type_dict = {}\n",
    "    i = 0\n",
    "    list1 = []\n",
    "    while i < len(token_list) - 1:\n",
    "        if tag_list[i] == tag_type:\n",
    "            if tag_list[i+1] == tag_type:\n",
    "                list1 += [(token_list[i] + \" \" +  token_list[i+1], tag_type)]\n",
    "                \n",
    "            else:\n",
    "                list1 += [(token_list[i], tag_type)]\n",
    "        i += 1\n",
    "    return list1\n",
    "\n",
    "\n",
    "people_dict = {}\n",
    "people_list1 = tag_type(token_list, entity_tags, 'PERSON')\n",
    "for item in people_list1:\n",
    "    if len(item[0]) > 2:\n",
    "        people_dict[item[0]] = people_dict.get(item[0], 0) + 1\n",
    "people_list2 = []\n",
    "for item, count in people_dict.items():\n",
    "    people_list2 += [(item, count)]\n",
    "sorted_people_list = sorted(people_list2, key = lambda tup: tup[1], reverse = True)\n",
    "most_referred_people = sorted_people_list[:30]\n",
    "print(\"30 Most common strings referring to PEOPLE\", '\\n', most_referred_people, '\\n')\n",
    "\n",
    "places_dict = {}\n",
    "places_list1 = tag_type(token_list, entity_tags, 'LOC') + tag_type(token_list, entity_tags, 'GPE')\n",
    "for item in places_list1:\n",
    "    places_dict[item[0]] = places_dict.get(item[0], 0) + 1\n",
    "places_list2 = []\n",
    "for item, count in places_dict.items():\n",
    "    places_list2 += [(item, count)]\n",
    "sorted_places_list = sorted(places_list2, key = lambda tup: tup[1], reverse = True)\n",
    "most_referred_places = sorted_places_list[:30]\n",
    "print(\"30 Most common strings referring to PLACES\", '\\n', most_referred_places)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function display_sent creates the column names for the table that will be used to store the tokens with corrosponding given tags. For example the token Anne is of type People and would have a corrosponding tag `PER`. The columns lower will be used to translate the tokens such as *Captain* into captain. This is needed as captain can be used as a role, or can be used as a title. The lemma column ensures that any plurals are reverted into the singular form of the word. An example in mysample could be years into year. IOB labels not used here as by using IOB labels, this creates many of the same tags next to eachother which is not wanted, since this could lead it to believe many nouns close could be listed incorrectly as one NE. This function goes through every token in the sentences and adds various data to the information list, returning the table with the tokens, lower case representations, lemmas, pos tags and NER tags\n",
    "\n",
    "Token_func function creates a list for the token, POS tags and entity tags. For every sentence add the specific values to the specific lists. i.e. add the tokens to the token lists, post tags to the POS tags list and entity tags to entity_tag list.\n",
    "\n",
    "Tag type function creates a dictionary to store the tag types by going through each token and checks if its corresponding tag type is equivalent to the given tag type. Then checks if there are two tokens in a row with the same tag type and assumes that they are part of the same item i.e. Mr Elliot would both have the same NER tag PERSON, so will be grouped together as one item. If this isnt the case just adds just the singular item to the tag list.\n",
    "\n",
    "The code then gets a list of all tokens with the tag type 'PERSON' using the function tag_type with the paramter PERSON. Then stores each item, in the list, in a dictionary with a count of how many times they occur. This is needed as we need to find the 30 most common strings, so the number of occurences corrspond to how common the string is. Then adds each person and count into a list of tuples, ordering the list of tuples in descending order of count, having the most common first, printing just the first 30 in the list using the code `sorted_people_list[:30]`\n",
    "\n",
    "Now we do the similar effect but using the tag LOC (for location). This is because a place is a location. The tag GPE is also used as geo-political entity which means the same as a place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Making reference to specific examples from the text in `mysample`, **discuss** the different types of errors made by the named entity recogniser. \\[6 marks\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One error made the named entity recogniser is that Mrs Musgrove, who is a person (we know this from the title **Mrs**) has been labelled as a location (LOC) or a GPE. We know this as she is outputted above as one of the most common strings referring to a place. This is due to the word `Musgrove` having multiple meaning or in other words having Entity Ambiguity. This is because in this sample Musgrove has been used as a surname for a person, one of its meanings, however the named entity recogniser knows that this is also the name of the `location` **Musgrove park hospital**, therefore has been labelled incorrectly in this instance. Another example of a token being given multiple NER tag's is the token `Benwick`. This was given the NER tag ORG, specifying that is an organisation, yet is also a village and civil parish in the Fenland district of Cambridgeshire, England, so could be given the tag `LOC` or GPE. Another type error made by the named entity recogniser is the token `Smith`. This is because there may be two occurences of the name and may refer to different people, since it is known to be a very common name in England, yet they are both tagged as PERSON so we would not know which one of the people if there was more than one, was being referenced.\n",
    "\n",
    "In addition, tokens such as `Aunt` and `Anne` which both mean the same thing, i.e. **name variation.** For example these two tokens at a time may be referring to the same person (Anne), however as we do not know the full context of the corpus, so could be possibly mis-tagged. However, even if we knew that `Anne` could be reffered to as `his aunt`, the use of `aunt`, could also be used to refer to other people, for example another female mentioned `Mrs Clay`. This makes it very difficult to link named entities using the named entity recogniser. \n",
    "\n",
    "`Name variation` and `entity ambiguity` are the two main problems with `entity linking`. Sorting one of these out, for example sorting out the name variation, increases the problem with ambiguity. this is because by giving a word more like words, when deciding what a word means, there are now even more options that the word could now mean. An example of this could be giving Aunt as another definition for Mrs Clay, the name variation would reduce the problem for name variation, but would increase the problem for entity ambiguity when deciding which meaning to go with when faced with the entity Aunt. The fact that an entity can be of different types and the fact that a string may refer to multiple named entities makes it difficult to link the the classified type and named entity. To reduce ambiguity, techniques such as feature extraction can be used.\n",
    "\n",
    "In my output, examples of:\n",
    "- false positives are in Location, Mrs Wallis, Mrs Musgrove and Lyme who are all People\n",
    "- false negatives are **Cobb** is a location not listed in the locations\n",
    "- An example of a mis-classification error is `temple` has been listed as a location when talked about `rub her temple` i.e. the case of someone head. Misclassification errors lead to boundary errors when calculating precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) **Design** and **implement** a system to track the locations of characters throughout the story.  For a given PERSON named entity, your system should return a list of time-ordered LOCATIONS for that character.  Test your system using the complete text of \"Persuasion\" (**not** `mysample`) for at least 3 major characters.   \\[13 marks\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete this task an entity linking technqiue must be used. The goal of named entity linking is to either return:\n",
    "- Conical entities in KB of entry being mentioned\n",
    "- NIl if entry does not exist\n",
    "\n",
    "The techniques for entity linking are:\n",
    "\n",
    "- Step 1: Find candidates within Kb (Knowledge base) for given rnitity mention\n",
    "- Step 2: Rank candidates to find most probable\n",
    "\n",
    "When generating candidates, we must address the name variation problem, while finding all potential revelant candidates. This leads to a trade off between precision & recall. We need a high recall so that correct entities is among the candidates, but this hurts precision and efficiency. In my solution only 3 characters will be **tracked**, so efficiency isnt too much of a problem, but I will expect there to be a lack of precision (when compared to recall).\n",
    "\n",
    "The strategies for generating candidates will include ignoring context, and the mention is an exact match. With more experience strategies such as substring mentions and acroynm mentions can be used, and I will attempt to implement these if possible. By ignoring context, this increases recall, getting as many candidates as possible, while getting the exact match increases precision.\n",
    "\n",
    "Using string simmularity to generate candidates is a viable method to entity linking. This helps towards the problem with name variations, but at the same time increases the problem with ambiguity. An example of this that I will implement is the `Levenshtein Distance`, also known as the **Minimum Edit Distance** The Levenshtein distance between 2 is the numner of:\n",
    "\n",
    "- Insertions\n",
    "- Deletions\n",
    "- Substitutions.\n",
    "\n",
    "required to transform one string to the other. A benefit of using this is that, maybe not in this case, but errors in spelling could lead to entity linking. Moreover this helps with entity linking with the use of nicknames, as it can see the two words are similar. An example of Levenshtein is shown below:\n",
    "![Levenstein Example](leven.gif) <br>\n",
    "Ranking of candidates is not needed, as we are returning a complete list of locations in order found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list, tag_list, entity_tags = token_func(nlp_persuasion)\n",
    "people_list1 = tag_type(token_list, entity_tags, 'PERSON')\n",
    "\n",
    "for item in people_list1:\n",
    "    if len(item[0]) > 2:\n",
    "        people_dict[item[0]] = people_dict.get(item[0], 0) + 1\n",
    "places_dict = {}\n",
    "places_list1 = tag_type(token_list, entity_tags, 'LOC') + tag_type(token_list, entity_tags, 'GPE')\n",
    "for item in places_list1:\n",
    "    if len(item[0]) > 2:\n",
    "        places_dict[item[0]] = places_dict.get(item[0], 0) + 1\n",
    "\n",
    "def levenshtein_distance(word1, word2):\n",
    "    lev_dis = 0\n",
    "    word1_length = len(word1)\n",
    "    word2_length = len(word2)\n",
    "    if word1_length > word2_length:\n",
    "        lev_dis += word1_length - word2_length\n",
    "    else:\n",
    "        lev_dis += word2_length - word1_length\n",
    "    for i in range(0, min(word1_length, word2_length)):\n",
    "        if word1[i] != word2[i]:\n",
    "            lev_dis += 1\n",
    "    return lev_dis\n",
    "\n",
    "\n",
    "\n",
    "def location_tracker(person, text):\n",
    "    location_list = []\n",
    "    close_words = [person]\n",
    "    sentences_to_search = []\n",
    "  \n",
    "    for key in people_dict.keys():\n",
    "        if person in key and key not in close_words:\n",
    "            close_words += [key]\n",
    "    for sentence in text:\n",
    "        i=0\n",
    "        while i < len(sentence) - 2:\n",
    "            if levenshtein_distance(person, (str(sentence[i]) + \" \" + str(sentence[i+1])+ \" \" + str(sentence[i+2]))) < 5 and (str(sentence[i]) + \" \" + str(sentence[i+1])+ \" \" + str(sentence[i+2])) not in close_words:\n",
    "                close_words += [str(sentence[i]) + \" \" + str(sentence[i+1])+ \" \" + str(sentence[i+2])]\n",
    "            elif levenshtein_distance(person, (str(sentence[i]) + \" \" + str(sentence[i+1]))) < 5 and (str(sentence[i]) + \" \" + str(sentence[i+1])) not in close_words:\n",
    "                close_words += [str(sentence[i]) + \" \" + str(sentence[i+1])]\n",
    "            elif levenshtein_distance(person, (str(sentence[i]))) < 3 and str(sentence[i]) not in close_words:\n",
    "                close_words += [str(sentence[i])]\n",
    "            i = i + 1\n",
    "    for sentence in text:\n",
    "        i = 0\n",
    "        while i < len(sentence) - 2:\n",
    "            if (str(sentence[i]) + \" \" + str(sentence[i+1]) + \" \" + str(sentence[i+2])) in close_words and sentence not in sentences_to_search:\n",
    "                sentences_to_search += [sentence]\n",
    "            elif (str(sentence[i]) + \" \" + str(sentence[i+1])) in close_words and sentence not in sentences_to_search:\n",
    "                sentences_to_search += [sentence]\n",
    "            elif (str(sentence[i])) in close_words and sentence not in sentences_to_search:\n",
    "                sentences_to_search += [sentence]\n",
    "            i = i+1\n",
    "    for sentence in sentences_to_search:\n",
    "        locations_in_sentence = []\n",
    "        i = 0\n",
    "        while i < len(sentence):\n",
    "            if str(sentence[i]) + \" \" + str(sentence[i+1]) in places_dict.keys():\n",
    "                locations_in_sentence += [str(sentence[i]) + \" \" + str(sentence[i+1])]\n",
    "            elif str(sentence[i]) in places_dict.keys():\n",
    "                locations_in_sentence += [str(sentence[i])]\n",
    "            i += 1\n",
    "        if len(locations_in_sentence) > 0:\n",
    "            location_list += [locations_in_sentence]\n",
    "    return location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walter Elliot has been at these locations [['Kellynch'], ['Esq .'], ['Bath'], ['Esq .'], ['Kellynch', 'Somersetshire'], ['Anne', 'Anne'], ['London', 'Bath'], ['Cheshire', 'Dugdale', 'Kellynch', 'Esq .']] \n",
      "\n",
      "Russell has been at these locations [['Kellynch'], ['Wentworth', 'Harville', 'Anne', 'Benwick'], ['Kellynch', 'Anne'], ['Harville'], ['Benwick'], ['Anne', 'Captain Wentworth', 'Wentworth'], ['Anne'], ['Anne', 'Bath', 'Uppercross Cottage', 'Cottage', 'Kellynch'], ['Bath'], ['Anne', 'Captain Wentworth', 'Wentworth'], ['Bath'], ['Benwick'], ['Captain Wentworth', \"Wentworth 's\"], ['Uppercross'], ['Harville', 'Captain Wentworth', 'Wentworth'], ['Anne'], ['Anne'], ['Anne', 'Camden Place', 'Place'], ['Lyme'], ['Anne'], ['Uppercross', 'Captain Wentworth', \"Wentworth 's\"], ['Anne', 'Anne'], ['Kellynch'], ['Benwick'], ['Anne'], ['Anne'], ['Wallis'], ['Anne'], ['Kellynch', 'Bath'], ['Camden Place', 'Place'], ['Anne'], ['Bath'], ['Uppercross', 'Kellynch'], ['Anne'], ['Anne'], ['Anne'], ['Anne'], ['Captain Wentworth', 'Wentworth', 'Captain Wentworth', 'Wentworth'], ['Anne', 'Captain Wentworth', 'Wentworth'], ['Anne', 'Kellynch'], ['Anne'], ['Anne', 'Camden Place', 'Place'], ['Bath', 'Camden Place', 'Place'], ['Camden Place', 'Place'], ['Uppercross', 'Musgrove', 'Harville'], ['Anne'], ['Harville', 'Harville'], ['Captain Wentworth', \"Wentworth 's\", 'Anne', 'Mrs Musgrove', \"Musgrove 's\", 'Mrs Musgrove', 'Musgrove'], ['Anne'], ['Benwick'], ['the Concert', 'Concert Room', 'Room'], ['Mrs Musgrove', \"Musgrove 's\", 'Anne'], ['Anne', 'Bath', 'Kellynch', 'Anne', 'Bath'], ['Bath'], ['Kellynch'], ['Anne'], ['Kellynch', 'Kellynch'], ['Musgrove', 'Anne'], ['Anne'], ['Anne'], ['Anne', 'Anne', 'Uppercross'], ['Kellynch'], ['Anne', 'Kellynch'], ['Bath'], ['Anne'], ['Uppercross'], ['Harville'], ['Anne'], ['Bath', 'Kellynch'], ['Anne'], ['Anne', 'Uppercross Cottage', 'Cottage'], ['Anne'], ['Anne'], ['Captain Wentworth', 'Wentworth'], ['Mrs Musgrove', 'Musgrove'], ['Anne'], ['Captain Wentworth', 'Wentworth'], ['Harville', 'Benwick'], ['Anne'], ['Anne', 'Musgrove'], ['Musgrove', 'Captain Wentworth', 'Wentworth'], ['Kellynch'], ['Captain Wentworth', \"Wentworth 's\"], ['Anne', 'Anne'], ['Uppercross'], ['Captain Wentworth', 'Wentworth'], ['Cottage'], ['Anne'], ['Anne', 'Captain Wentworth', 'Wentworth'], ['Camden Place', 'Place'], ['Kellynch'], ['Uppercross'], ['Captain Wentworth', 'Wentworth'], ['Mrs Musgrove', \"Musgrove 's\"], ['Anne', 'Benwick'], ['the Concert', 'Concert Room', 'Room'], ['Anne'], ['Musgrove', 'Benwick'], ['Musgrove'], ['Anne'], ['Uppercross', 'Kellynch', 'Bath'], ['Mackenzie'], ['Anne'], ['Musgrove', 'Anne'], ['Anne', 'London'], ['Anne'], ['Wallis'], ['Anne'], ['Anne'], ['Anne'], ['Bath', 'London', 'Kellynch', 'Bath'], ['Captain Wentworth', 'Wentworth', \"Musgrove 's\"], ['Kellynch'], ['Uppercross', 'Camden Place', 'Place', 'Anne', 'Lyme', 'Musgrove', 'Benwick', 'Camden Place', 'Place'], ['Anne', 'Wallis'], ['Anne', 'Captain Wentworth', 'Wentworth'], ['Westgate Buildings', 'Buildings', 'Anne'], ['Captain Wentworth', 'Wentworth'], ['Lyme', 'Camden Place', 'Place', 'Anne']] \n",
      "\n",
      "Charles has been at these locations [['Kellynch'], ['Benwick', 'Anne', 'Captain Wentworth', 'Wentworth'], ['Anne'], ['Anne', 'Captain Wentworth', 'Wentworth'], ['Anne', 'Benwick'], ['Captain Wentworth', 'Wentworth', 'Anne'], ['Captain Wentworth', 'Wentworth'], ['Anne'], ['Captain Wentworth', 'Wentworth'], ['Anne'], ['Anne', 'Captain Wentworth', 'Wentworth'], ['Uppercross'], ['Anne', 'Captain Wentworth', 'Wentworth', 'Benwick'], ['Anne'], ['Kellynch', 'Bath'], ['Exeter'], ['Cottage', \"Musgrove 's\"], ['Winthrop'], ['Anne'], ['Anne', 'Captain Wentworth', 'Wentworth'], ['Captain Wentworth', 'Wentworth', 'Captain Wentworth', 'Wentworth', 'Anne'], ['Musgrove', 'Anne', 'Anne'], ['Uppercross'], ['Cottage', 'Anne', 'Captain Wentworth', 'Wentworth', 'Captain Wentworth', 'Wentworth', 'Captain Wentworth', 'Wentworth'], ['Mrs Musgrove', 'Musgrove', 'Uppercross', 'Captain Wentworth', 'Wentworth', 'Musgrove', \"Musgrove 's\"], ['Captain Wentworth', 'Wentworth'], ['Captain Wentworth', 'Wentworth'], ['Harville', 'Harville'], ['Esq .'], ['Monkford'], ['Captain Wentworth', \"Wentworth 's\"], ['Anne'], ['Anne'], ['Captain Wentworth', 'Wentworth'], ['Mrs Musgrove', \"Musgrove 's\", 'Anne'], ['Harville'], ['Captain Wentworth', 'Wentworth', 'Captain Wentworth', 'Wentworth'], ['Anne'], ['Captain Wentworth', 'Wentworth'], ['Musgrove', 'Benwick'], ['Anne', 'Captain Wentworth', 'Wentworth', 'Cottage'], ['Musgrove', 'Anne'], ['Anne'], ['Musgrove'], ['Mrs Musgrove', 'Musgrove', 'Anne'], ['Captain Wentworth', 'Wentworth'], ['Musgrove'], ['Lyme'], ['Anne', 'Mrs Musgrove', 'Musgrove', 'Harville', 'Wentworth'], ['Captain Wentworth', 'Wentworth'], ['Captain Wentworth', 'Wentworth', 'Anne'], ['Captain Wentworth', 'Wentworth'], ['Musgrove', 'Esq .', 'Uppercross'], ['Anne'], ['Captain Wentworth', 'Wentworth', 'Anne'], ['Anne'], ['Musgrove', 'Captain Wentworth', 'Wentworth'], ['Musgrove'], ['Captain Wentworth', 'Wentworth'], ['Musgrove', 'Captain Wentworth', 'Wentworth', 'Cottage'], ['Mrs Musgrove', 'Musgrove'], ['Musgrove', 'Anne'], ['Anne', 'Anne'], ['Anne'], ['Lyme'], ['Uppercross'], ['Anne'], [\"Musgrove 's\", 'Captain Wentworth', 'Wentworth', 'Lyme'], ['Captain Wentworth', 'Wentworth'], ['Bath'], ['Anne'], ['Lyme', 'Harville', 'Mrs Musgrove', 'Musgrove', 'Lyme'], ['Anne', 'Anne'], ['Mrs Musgrove', \"Musgrove 's\", 'Room'], ['Lyme', 'Mrs Musgrove', \"Musgrove 's\", 'Anne'], ['Musgrove'], ['Bath'], ['Harville', 'Anne'], ['Musgrove', 'Anne'], [\"Wentworth 's\", 'Laconia', 'Laconia'], ['Musgrove', 'Anne'], ['Anne'], ['Anne'], ['to Plymouth', 'Plymouth', 'Benwick', 'Benwick', 'Kellynch'], ['Cheshire', 'Dugdale', 'Kellynch', 'Esq .'], ['Musgrove'], ['Musgrove', 'Anne'], ['china', 'Anne', 'Uppercross'], ['Captain Wentworth', 'Wentworth'], ['Anne', 'Captain Wentworth', 'Wentworth'], ['Bath', 'London']] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Walter Elliot has been at these locations\", location_tracker(\"Walter Elliot\", nlp_persuasion), '\\n')\n",
    "print(\"Russell has been at these locations\", location_tracker(\"Russell\", nlp_persuasion), '\\n')\n",
    "print(\"Charles has been at these locations\", location_tracker(\"Charles\", nlp_persuasion ),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code works by first of all makeing sure that all the items in the dictionary of people has a length greater than \n",
    "2, this is to exclude anything that may be wrongly tagged as a person as peoples names tend be longer than 2. The same is then done for the  dictionary of places/locations.\n",
    "\n",
    "The next function is used to calcuate the Levenshtein Distance. This finds similar words to the word passed in the location tracker. It does this by creating a list of words which are assumed to be close to the person i.e. *Anne .... England*. We then look for close words for the names of the people for example if `Benwick` is mentioned we also want to look for `Captain Benwick`. The difference in is then length to the value of the Levenshtein Distance and calculates the number of changes required to make one word equal to the other.\n",
    "\n",
    "The location tracker function starts by finding words that would be close to the person using the Levenshtein Distance\n",
    "calculated. Here i haved used a distance of 5 to assume tbey are close. By checking for at maximum 3 words in a row this increases the number of possible candidates, increasing the recall. Continues to searchs through the sentences to see where the close words occur, and if any of the close words occur in the sentence, add these sentence to a list of sentences to be searched for locations. Finally goes through each of sentences in sentences-to-search to find locations, checking up to two words to see if the words occur in the dictionary of places. When a location is found, its added to a list for each sentence. If the length of the list of locations is not empty, then add it to the list of total locations for that person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my results I can say that my location tracker funciton has a very **high recall**, returing alot of possible candidtes for each person. The reason for a small test on a character such as walter Elliot is due the lack of performace on this machine, along with wanting to see if less common people return lists of a decent size. By analysing the results I can also determine that the precision of my tracker is not very good. This is because I decided to maximise recall, to ensure all possible candidates are considered. I know my precision is bad as Names such as `Mrs Musgrove`, `Anne` and `Captain Wentworth` are retruned within the list of locations. To improve this, you could implement features such as using a large KB to improve precsion, but in turn would reduce recall along with efficiency, which i tried to maximise within this funciton. I do know my function is somewhat precise however when looking at the results of Walter Elliot, with the majoirty of the locations being tagged correctly as well as being recalled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
